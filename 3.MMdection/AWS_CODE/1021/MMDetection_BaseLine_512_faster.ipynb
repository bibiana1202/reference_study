{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEvRfvpLTw_o"
      },
      "source": [
        "\n",
        "MMDetection tutorial을 활용하여 베이스라인을 만들었습니다.\n",
        "\n",
        "coco format으로 변환하는 부분은 이여름님께서 공유해주신 [코드](https://dacon.io/competitions/official/235855/codeshare/3729)를 참고했고\n",
        "\n",
        "데이터 정제 과정과 추론 부분은 데이콘에서 제공해 주신 [베이스라인](https://dacon.io/competitions/official/235855/codeshare/3725)을 참고했습니다.\n",
        "\n",
        "\n",
        "**참고 링크** <p>\n",
        "- [이여름님의 코드](https://dacon.io/competitions/official/235855/codeshare/3729)\n",
        "- [데이콘 베이스라인](https://dacon.io/competitions/official/235855/codeshare/3725)\n",
        "- [colab version tutorial](https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb)\n",
        "- [kaggle notebook](https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer?scriptVersionId=68887943&cellId=21)\n",
        "\n",
        "\n",
        "**MMDetection 관련 링크**\n",
        "- [mmdetection github](https://github.com/open-mmlab/mmdetection)\n",
        "- [mmdetection docs](https://mmdetection.readthedocs.io/)\n",
        "- [model_zoo](https://mmdetection.readthedocs.io/en/latest/model_zoo.html#baselines)\n",
        "\n",
        "*❗❗* 코드는 모든 학습 데이터를 사용할 수 있도록 해놓았지만 출력은 일부 데이터만 사용한 결과물이며 로컬 환경과 코랩 환경을 오가며 진행했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RogFIyia62lO"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge\n",
        "\n",
        "pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.10.0/index.html\n",
        "\n",
        "git clone https://github.com/open-mmlab/mmdetection.git\n",
        "\n",
        "pip install -r requirements/build.txt\n",
        "\n",
        "pip install pycocotools-windows\n",
        "\n",
        "pip install -v -e .\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f6ZQQOUz7Hkg"
      },
      "outputs": [],
      "source": [
        "# basic setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import base64\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm.notebook import tqdm\n",
        "from glob import glob\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "base_dir = \"/home/ubuntu/mmdet512/input\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ubuntu/mmdet512'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr7x8bXyzfyF",
        "outputId": "e3549e33-d422-461f-d2a8-8abfc41add03"
      },
      "outputs": [],
      "source": [
        "os.makedirs('./input', exist_ok=True)\n",
        "os.makedirs('./output', exist_ok=True)\n",
        "%cd input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/mmdet512/input\n"
          ]
        }
      ],
      "source": [
        "cd /home/ubuntu/mmdet512/input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W6GoGaJDqh76",
        "outputId": "208c3740-5e36-44f7-a73e-96585cb53703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>class_id</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>4</td>\n",
              "      <td>170.092308</td>\n",
              "      <td>301.369863</td>\n",
              "      <td>406.892308</td>\n",
              "      <td>401.315068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>11</td>\n",
              "      <td>440.369231</td>\n",
              "      <td>378.958904</td>\n",
              "      <td>461.538462</td>\n",
              "      <td>436.602740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>12</td>\n",
              "      <td>440.369231</td>\n",
              "      <td>378.958904</td>\n",
              "      <td>461.538462</td>\n",
              "      <td>436.602740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>4</td>\n",
              "      <td>170.338462</td>\n",
              "      <td>301.369863</td>\n",
              "      <td>407.876923</td>\n",
              "      <td>394.301370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>4</td>\n",
              "      <td>169.600000</td>\n",
              "      <td>287.780822</td>\n",
              "      <td>410.092308</td>\n",
              "      <td>386.410959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67774</th>\n",
              "      <td>52951d7de2485aba8ed62629eee4d254</td>\n",
              "      <td>10</td>\n",
              "      <td>67.333333</td>\n",
              "      <td>256.355556</td>\n",
              "      <td>85.111111</td>\n",
              "      <td>268.088889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67775</th>\n",
              "      <td>52951d7de2485aba8ed62629eee4d254</td>\n",
              "      <td>4</td>\n",
              "      <td>163.111111</td>\n",
              "      <td>279.288889</td>\n",
              "      <td>358.666667</td>\n",
              "      <td>336.355556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67848</th>\n",
              "      <td>1224f07d895107573588225f692e94f9</td>\n",
              "      <td>1</td>\n",
              "      <td>250.729412</td>\n",
              "      <td>161.922261</td>\n",
              "      <td>320.250980</td>\n",
              "      <td>223.434629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67849</th>\n",
              "      <td>1224f07d895107573588225f692e94f9</td>\n",
              "      <td>1</td>\n",
              "      <td>262.525490</td>\n",
              "      <td>155.590106</td>\n",
              "      <td>319.247059</td>\n",
              "      <td>221.399293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67850</th>\n",
              "      <td>1224f07d895107573588225f692e94f9</td>\n",
              "      <td>1</td>\n",
              "      <td>260.015686</td>\n",
              "      <td>154.007067</td>\n",
              "      <td>318.996078</td>\n",
              "      <td>218.459364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36096 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               image_id  class_id       x_min       y_min  \\\n",
              "6      9a5094b2563a1ef3ff50dc5c7ff71345         4  170.092308  301.369863   \n",
              "7      9a5094b2563a1ef3ff50dc5c7ff71345        11  440.369231  378.958904   \n",
              "8      9a5094b2563a1ef3ff50dc5c7ff71345        12  440.369231  378.958904   \n",
              "9      9a5094b2563a1ef3ff50dc5c7ff71345         4  170.338462  301.369863   \n",
              "10     9a5094b2563a1ef3ff50dc5c7ff71345         4  169.600000  287.780822   \n",
              "...                                 ...       ...         ...         ...   \n",
              "67774  52951d7de2485aba8ed62629eee4d254        10   67.333333  256.355556   \n",
              "67775  52951d7de2485aba8ed62629eee4d254         4  163.111111  279.288889   \n",
              "67848  1224f07d895107573588225f692e94f9         1  250.729412  161.922261   \n",
              "67849  1224f07d895107573588225f692e94f9         1  262.525490  155.590106   \n",
              "67850  1224f07d895107573588225f692e94f9         1  260.015686  154.007067   \n",
              "\n",
              "            x_max       y_max  \n",
              "6      406.892308  401.315068  \n",
              "7      461.538462  436.602740  \n",
              "8      461.538462  436.602740  \n",
              "9      407.876923  394.301370  \n",
              "10     410.092308  386.410959  \n",
              "...           ...         ...  \n",
              "67774   85.111111  268.088889  \n",
              "67775  358.666667  336.355556  \n",
              "67848  320.250980  223.434629  \n",
              "67849  319.247059  221.399293  \n",
              "67850  318.996078  218.459364  \n",
              "\n",
              "[36096 rows x 6 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./train.csv', index_col = 0)\n",
        "df = df[df['class_id'] != 14]\n",
        "df['class_id'] = df['class_id'] + 1\n",
        "df = df[['image_id', 'class_id', 'x_min', 'y_min', 'x_max', 'y_max']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pvrIC3SK_vwf"
      },
      "outputs": [],
      "source": [
        "def convert_to_coco(name_list, df, save_path): # 변경\n",
        "\n",
        "  res = defaultdict(list)\n",
        "    \n",
        "  categories = {\n",
        "      'Aortic enlargement': 1,\n",
        "      'Atelectasis': 2,\n",
        "      'Calcification': 3,\n",
        "      'Cardiomegaly': 4,\n",
        "      'Consolidation': 5,\n",
        "      'ILD': 6,\n",
        "      'Infiltration': 7,\n",
        "      'Lung Opacity': 8,\n",
        "      'Nodule/Mass': 9,\n",
        "      'Other lesion': 10,\n",
        "      'Pleural effusion': 11,\n",
        "      'Pleural thickening': 12,\n",
        "      'Pneumothorax': 13,\n",
        "      'Pulmonary fibrosis': 14\n",
        "  }\n",
        "    \n",
        "  df = df[df['image_id'].isin(name_list)]\n",
        "  names = df['image_id'].unique()\n",
        "  n_id = 0\n",
        "\n",
        "  for pic_name in tqdm(names):\n",
        "\n",
        "    df_temp = df[df['image_id'] == pic_name]\n",
        "    tmp = df_temp.values\n",
        "\n",
        "    # images\n",
        "    res['images'].append({\n",
        "        'id': pic_name,\n",
        "        'width': 512,\n",
        "        'height': 512,\n",
        "        'file_name': pic_name+\".png\"\n",
        "    })\n",
        "    \n",
        "    # annotations\n",
        "    for shape in tmp:\n",
        "        x1, y1, x2, y2 = shape[2], shape[3], shape[4], shape[5]\n",
        "        \n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        \n",
        "        res['annotations'].append({\n",
        "            'id': n_id,\n",
        "            'image_id': pic_name,\n",
        "            'category_id': shape[1],\n",
        "            'area': w * h,\n",
        "            'bbox': [x1, y1, w, h],\n",
        "            'iscrowd': 0,\n",
        "        })\n",
        "        n_id += 1\n",
        "    \n",
        "# categories    \n",
        "  for name, id in categories.items():\n",
        "      res['categories'].append({\n",
        "          'id': id,\n",
        "          'name': name,\n",
        "      })\n",
        "  # return res\n",
        "  with open(save_path, 'w') as f:\n",
        "      json.dump(res, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFHJB8WhBKHW",
        "outputId": "2653e5e5-997f-4993-f8eb-43928a3b21d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "split_num : 878\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(3516, 878, 4394)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random.seed(10)\n",
        "\n",
        "# train_files = glob(os.path.join(base_dir, 'train/*.png'))\n",
        "# train_files = os.listdir('./input/train')\n",
        "# train_files = list(map(del_extension, train_files))\n",
        "train_files = df['image_id'].unique()\n",
        "\n",
        "random.shuffle(train_files)\n",
        "\n",
        "# 8:2로 학습/검증 데이터 분리\n",
        "split_num = int(len(train_files)*0.2)\n",
        "print(\"split_num :\", split_num)\n",
        "\n",
        "train_file = train_files[split_num:]\n",
        "valid_file = train_files[:split_num]\n",
        "\n",
        "len(train_file), len(valid_file),len(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "643b91e104c54e6597f65476fb186b08",
            "248db45df90c486b8c7425e2fa99df82",
            "386f84edab764cd2be78ecdadd696786",
            "a548af1bca1c492aa942e66d9e0dd43e",
            "d537ede18db94f24889a3736af33c412",
            "407d88b1e12f4544b3b5f9f2e698dd39",
            "108f45e280b24f44836e4df715891af5",
            "a2e6a598b7fe4768adb163b2434ceba9",
            "ac2cb33dd3f64609a96bfc82da0579b6",
            "5f214eac68ee48b3b69c198f10d1f383",
            "d3b2f8ad41f74bcb857a67a901ffe3e4"
          ]
        },
        "id": "u-d3X1l4BunK",
        "outputId": "524a86af-e75c-4016-bfe7-8e3cc1a274a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdcc0430e5a54b8ba775d2f217408f62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3516 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "convert_to_coco(train_file, df, os.path.join(base_dir, 'train_annotations.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "80a6c16992674c6ea87dc15dc33588a0",
            "73685fe8004d4d3fae52beb4eab712e5",
            "c4e8736f4dd04726aef6464cd69ab74b",
            "cb006118a674438a8ac0c3b7eeaabaec",
            "2d029adb381e4e47ba3da0108560fc20",
            "1e2411c8c715496fa92ffddee4347d62",
            "7fbfc7fe65674abfb5e3819aa9616b7d",
            "487909f72eb84fad8571115f72981f6c",
            "cfc9b2667c36433f85ac86f2d09bea31",
            "e3feb19df1b44362b34d44ff06ceeeed",
            "f59fb9933ecf44e4a612e2eeaf07d544"
          ]
        },
        "id": "MWjcp4UHBvri",
        "outputId": "dbebd543-7111-4977-e59a-600f3161a87e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf2792b92c404212b21db64d39766be7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/878 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "convert_to_coco(valid_file, df, os.path.join(base_dir, 'valid_annotations.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbbR6VMUH7bL"
      },
      "source": [
        "## Environment setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JO7oCKbK2-f",
        "outputId": "7205cc68-d52b-4557-9706-69957d2bbadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Tue_Mar__8_18:18:20_PST_2022\n",
            "Cuda compilation tools, release 11.6, V11.6.124\n",
            "Build cuda_11.6.r11.6/compiler.31057947_0\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEtOBfmtK8w2",
        "outputId": "855dfde4-682f-4375-d39b-45eb677b86e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 1.10.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /home/ubuntu/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages\n",
            "Requires: typing_extensions\n",
            "Required-by: timm, torchaudio, torchvision\n"
          ]
        }
      ],
      "source": [
        "!pip show torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rreI4H5UNN8X"
      },
      "source": [
        "런타임 다시 시작하고 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/mmdet512\n"
          ]
        }
      ],
      "source": [
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55dEZ5ou9KJ",
        "outputId": "feea4fce-a0e9-456e-d6f8-d1ef01248b0a"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/open-mmlab/mmdetection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN3U71zKT2ay",
        "outputId": "2e93e28a-e857-412a-d624-2e836f212e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/mmdet512/mmdetection\n"
          ]
        }
      ],
      "source": [
        "%cd ./mmdetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZdfnvnD8yp9"
      },
      "source": [
        "========="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyK8Jr1LL_8O",
        "outputId": "eccc7a95-c17e-4ed8-987e-26936b85bc8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.0 True\n",
            "2.25.2\n",
            "11.3\n",
            "GCC 9.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ubuntu/mmdet512/mmdetection'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2vkUvb-NRwH",
        "outputId": "14e45ead-7144-4fd2-f019-1a6e554fe287"
      },
      "outputs": [],
      "source": [
        "# %cd mmdetection\n",
        "# !mkdir checkpoints\n",
        "# !wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
        "#       -O checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
        "\n",
        "# %cd mmdetection\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
        "      -O checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Eb2l7yvfH9cQ"
      },
      "outputs": [],
      "source": [
        "# Choose to use a config and initialize the detector\n",
        "config = \"/home/ubuntu/mmdet512/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py\"\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = '/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
        "# initialize the detector\n",
        "#model = init_detector(config, checkpoint, device='cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GrWIJywLV-V"
      },
      "source": [
        "## Train a detector on customized dataset\n",
        "\n",
        "To train a new detector, there are usually three things to do:\n",
        "1. Support a new dataset\n",
        "2. Modify the config\n",
        "3. Train a new detector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_knbBfkiEPIr"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import os.path as osp\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqJOpBe-bMj"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a detector using a pre-trained detector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hamZrlnH-YDD"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HntziLGq-92Z"
      },
      "source": [
        "Given a config that trains a Faster R-CNN on COCO dataset, we need to modify some values to use it for training Faster R-CNN on KITTI dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/mmdet512/input\n"
          ]
        }
      ],
      "source": [
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "base_path = '/home/ubuntu/mmdet512/input' \n",
        "%cd '/home/ubuntu/mmdet512/input'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ubuntu/mmdet512/input/work_dir'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_dir = os.path.join(base_path, \"work_dir\")\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "save_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb0FGH8aIrpj",
        "outputId": "99cfce8e-2055-440a-baa4-b026bc48f4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='FasterRCNN',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=14,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "        train_cfg=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        test_cfg=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100),\n",
            "        pretrained=None),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)))\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = '/home/ubuntu/mmdet512/input'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=8,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='train_annotations.json',\n",
            "        img_prefix='train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ],\n",
            "        data_root='/home/ubuntu/mmdet512/input',\n",
            "        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n",
            "                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n",
            "                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n",
            "                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
            "                 'Pulmonary fibrosis')),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='valid_annotations.json',\n",
            "        img_prefix='train',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='/home/ubuntu/mmdet512/input',\n",
            "        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n",
            "                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n",
            "                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n",
            "                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
            "                 'Pulmonary fibrosis')),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='valid_annotations.json',\n",
            "        img_prefix='test',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        data_root='/home/ubuntu/mmdet512/input',\n",
            "        classes=('Aortic enlargement', 'Atelectasis', 'Calcification',\n",
            "                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n",
            "                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n",
            "                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
            "                 'Pulmonary fibrosis')))\n",
            "evaluation = dict(interval=4, metric='bbox')\n",
            "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup=None,\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=30)\n",
            "checkpoint_config = dict(interval=4)\n",
            "log_config = dict(interval=8, hooks=[dict(type='TextLoggerHook')])\n",
            "custom_hooks = [dict(type='NumClassCheckHook')]\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '/home/ubuntu/mmdet512/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=2)\n",
            "work_dir = '/home/ubuntu/mmdet512/input/work_dir/faster/2'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "device = 'cuda'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "cfg.work_dir = save_dir+'/faster/2'\n",
        "\n",
        "val_anno = \"valid_annotations.json\"  \n",
        "test_anno = \"valid_annotations.json\" # 출력은 \"valid_partial_annotations.json\"\n",
        "train_anno = \"train_annotations.json\" # 출력은 \"train_partial_annotations.json\"\n",
        "\n",
        "# 이미지 폴더 설정\n",
        "train_img = \"train\" # 출력은 \"train_100000\"\n",
        "val_img = 'train'\n",
        "test_img =  \"test\"\n",
        "\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'CocoDataset'\n",
        "cfg.data_root = base_path\n",
        "\n",
        "#train\n",
        "cfg.data.train.type = 'CocoDataset'\n",
        "cfg.data.train.data_root = base_path\n",
        "cfg.data.train.ann_file = train_anno\n",
        "cfg.data.train.img_prefix = train_img\n",
        "\n",
        "#valid\n",
        "cfg.data.val.type = 'CocoDataset'\n",
        "cfg.data.val.data_root = base_path\n",
        "cfg.data.val.ann_file = val_anno\n",
        "cfg.data.val.img_prefix = val_img\n",
        "\n",
        "# test\n",
        "cfg.data.test.type = 'CocoDataset'\n",
        "cfg.data.test.data_root = base_path\n",
        "cfg.data.test.ann_file = test_anno\n",
        "cfg.data.test.img_prefix = test_img\n",
        "\n",
        "\n",
        "cfg.data.samples_per_gpu = 8\n",
        "cfg.data.workers_per_gpu = 2\n",
        "\n",
        "classes = (\n",
        "    'Aortic enlargement',\n",
        "    'Atelectasis',\n",
        "    'Calcification',\n",
        "    'Cardiomegaly',\n",
        "    'Consolidation',\n",
        "    'ILD',\n",
        "    'Infiltration',\n",
        "    'Lung Opacity',\n",
        "    'Nodule/Mass',\n",
        "    'Other lesion',\n",
        "    'Pleural effusion',\n",
        "    'Pleural thickening',\n",
        "    'Pneumothorax',\n",
        "    'Pulmonary fibrosis'\n",
        "    )\n",
        "\n",
        "cfg.data.train.classes = classes\n",
        "cfg.data.val.classes = classes\n",
        "cfg.data.test.classes = classes\n",
        "\n",
        "\n",
        "# modify num classes of the model in box head\n",
        "cfg.model.roi_head.bbox_head.num_classes = 14\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = \"/home/ubuntu/mmdet512/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\" # Error가 날 경우, \"/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\"\n",
        "\n",
        "################################################################ 파인튜닝 , 재학습, transfer learning(전이학습) ################################################################\n",
        "################################################################ 링크 파일 역할, training 조사 ################################################################\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "\n",
        "# 에폭 수 조절\n",
        "cfg.runner = dict(type='EpochBasedRunner', max_epochs=EPOCHS)\n",
        "\n",
        "cfg.log_config.interval = 8\n",
        "\n",
        "# Change the evaluation metric since we use customized dataset.\n",
        "#COCO dataset은 mmdetection에서 mAP metric을 지원하지 않아 VOC로 테스트\n",
        "cfg.evaluation.metric = 'bbox'\n",
        "# We can set the evaluation interval to reduce the evaluation times\n",
        "cfg.evaluation.interval = 4\n",
        "# We can set the checkpoint saving interval to reduce the storage cost\n",
        "cfg.checkpoint_config.interval = 4\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "cfg.device='cuda'\n",
        "\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "111W_oZV_3wa"
      },
      "source": [
        "### Train a new detector\n",
        "\n",
        "Finally, lets initialize the dataset and detector, then train a new detector!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "[\n",
            "CocoDataset Train dataset with number of images 3516, and instance counts: \n",
            "+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n",
            "| category               | count | category                | count | category          | count | category                | count | category          | count |\n",
            "+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+\n",
            "| 0 [Aortic enlargement] | 5793  | 1 [Atelectasis]         | 209   | 2 [Calcification] | 808   | 3 [Cardiomegaly]        | 4357  | 4 [Consolidation] | 441   |\n",
            "| 5 [ILD]                | 806   | 6 [Infiltration]        | 1042  | 7 [Lung Opacity]  | 1980  | 8 [Nodule/Mass]         | 2058  | 9 [Other lesion]  | 1742  |\n",
            "| 10 [Pleural effusion]  | 1921  | 11 [Pleural thickening] | 3834  | 12 [Pneumothorax] | 186   | 13 [Pulmonary fibrosis] | 3689  | -1 background     | 0     |\n",
            "+------------------------+-------+-------------------------+-------+-------------------+-------+-------------------------+-------+-------------------+-------+]\n"
          ]
        }
      ],
      "source": [
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "\n",
        "\n",
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "print(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4bjbys5R6gs",
        "outputId": "44f7b65d-50c7-4a7f-d237-56b979376999"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-21 03:23:08,722 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
            "2022-10-21 03:23:08,754 - mmdet - INFO - load checkpoint from local path: /home/ubuntu/mmdet512/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
            "2022-10-21 03:23:08,830 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([15, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([15]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([56, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([56]).\n",
            "2022-10-21 03:23:08,833 - mmdet - INFO - Start running, host: ubuntu@ip-172-31-69-122, work_dir: /home/ubuntu/mmdet512/input/work_dir/faster/2\n",
            "2022-10-21 03:23:08,834 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2022-10-21 03:23:08,834 - mmdet - INFO - workflow: [('train', 1)], max: 30 epochs\n",
            "2022-10-21 03:23:08,835 - mmdet - INFO - Checkpoints will be saved to /home/ubuntu/mmdet512/input/work_dir/faster/2 by HardDiskBackend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 22.20 GiB total capacity; 7.12 GiB already allocated; 19.06 MiB free; 7.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [27], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Create work_dir\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mmcv\u001b[39m.\u001b[39mmkdir_or_exist(osp\u001b[39m.\u001b[39mabspath(cfg\u001b[39m.\u001b[39mwork_dir))\n\u001b[0;32m----> 9\u001b[0m train_detector(model, datasets, cfg, distributed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, validate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/apis/train.py:244\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39melif\u001b[39;00m cfg\u001b[39m.\u001b[39mload_from:\n\u001b[1;32m    243\u001b[0m     runner\u001b[39m.\u001b[39mload_checkpoint(cfg\u001b[39m.\u001b[39mload_from)\n\u001b[0;32m--> 244\u001b[0m runner\u001b[39m.\u001b[39;49mrun(data_loaders, cfg\u001b[39m.\u001b[39;49mworkflow)\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             epoch_runner(data_loaders[i], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_run\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:53\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_iter \u001b[39m=\u001b[39m i\n\u001b[1;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mbefore_train_iter\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_iter(data_batch, train_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_train_iter\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_batch\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:31\u001b[0m, in \u001b[0;36mEpochBasedRunner.run_iter\u001b[0;34m(self, data_batch, train_mode, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_processor(\n\u001b[1;32m     29\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, data_batch, train_mode\u001b[39m=\u001b[39mtrain_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     30\u001b[0m \u001b[39melif\u001b[39;00m train_mode:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_step(data_batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[1;32m     32\u001b[0m                                     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mval_step(data_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py:77\u001b[0m, in \u001b[0;36mMMDataParallel.train_step\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     72\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmodule must have its parameters and buffers \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mon device \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj\u001b[39m}\u001b[39;00m\u001b[39m (device_ids[0]) but \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound one of them on device: \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m.\u001b[39mdevice\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m inputs, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscatter(inputs, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids)\n\u001b[0;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule\u001b[39m.\u001b[39;49mtrain_step(\u001b[39m*\u001b[39;49minputs[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs[\u001b[39m0\u001b[39;49m])\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/detectors/base.py:248\u001b[0m, in \u001b[0;36mBaseDetector.train_step\u001b[0;34m(self, data, optimizer)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(\u001b[39mself\u001b[39m, data, optimizer):\n\u001b[1;32m    222\u001b[0m     \u001b[39m\"\"\"The iteration step during training.\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[39m    This method defines an iteration step during training, except for the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39m              averaging the logs.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    249\u001b[0m     loss, log_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_losses(losses)\n\u001b[1;32m    251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    252\u001b[0m         loss\u001b[39m=\u001b[39mloss, log_vars\u001b[39m=\u001b[39mlog_vars, num_samples\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39m\u001b[39mimg_metas\u001b[39m\u001b[39m'\u001b[39m]))\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:116\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    114\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmethod of those classes \u001b[39m\u001b[39m{\u001b[39;00msupported_types\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mfp16_enabled\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m old_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    119\u001b[0m args_info \u001b[39m=\u001b[39m getfullargspec(old_func)\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/detectors/base.py:172\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monnx_export(img[\u001b[39m0\u001b[39m], img_metas[\u001b[39m0\u001b[39m])\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m return_loss:\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_train(img, img_metas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_test(img, img_metas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/detectors/two_stage.py:127\u001b[0m, in \u001b[0;36mTwoStageDetector.forward_train\u001b[0;34m(self, img, img_metas, gt_bboxes, gt_labels, gt_bboxes_ignore, gt_masks, proposals, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_train\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m                   img,\n\u001b[1;32m     92\u001b[0m                   img_metas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m                   proposals\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m                   \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     99\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m        img (Tensor): of shape (N, C, H, W) encoding input images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m        dict[str, Tensor]: a dictionary of loss components\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_feat(img)\n\u001b[1;32m    129\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    131\u001b[0m     \u001b[39m# RPN forward and loss\u001b[39;00m\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/detectors/two_stage.py:67\u001b[0m, in \u001b[0;36mTwoStageDetector.extract_feat\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_feat\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     66\u001b[0m     \u001b[39m\"\"\"Directly extract features from the backbone+neck.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(img)\n\u001b[1;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_neck:\n\u001b[1;32m     69\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneck(x)\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/backbones/resnet.py:643\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mfor\u001b[39;00m i, layer_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_layers):\n\u001b[1;32m    642\u001b[0m     res_layer \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, layer_name)\n\u001b[0;32m--> 643\u001b[0m     x \u001b[39m=\u001b[39m res_layer(x)\n\u001b[1;32m    644\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_indices:\n\u001b[1;32m    645\u001b[0m         outs\u001b[39m.\u001b[39mappend(x)\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/backbones/resnet.py:298\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    296\u001b[0m     out \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mcheckpoint(_inner_forward, x)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     out \u001b[39m=\u001b[39m _inner_forward(x)\n\u001b[1;32m    300\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/mmdet512/mmdetection/mmdet/models/backbones/resnet.py:289\u001b[0m, in \u001b[0;36mBottleneck.forward.<locals>._inner_forward\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    286\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_plugin(out, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_conv3_plugin_names)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     identity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownsample(x)\n\u001b[1;32m    291\u001b[0m out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m identity\n\u001b[1;32m    293\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/pytorch112_p38/lib/python3.8/site-packages/torch/nn/functional.py:2282\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2280\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2282\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2283\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2284\u001b[0m )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 22.20 GiB total capacity; 7.12 GiB already allocated; 19.06 MiB free; 7.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH=f'/home/ubuntu/mmdet512/output/model_faster/epoch_{EPOCHS}.pt'\n",
        "torch.save(model, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQ-yspZLuuI"
      },
      "source": [
        "## Test the trained detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo08PUlOav6_"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import inference_detector, show_result_pyplot\n",
        "base_path = '/home/ubuntu/mmdet512/input'\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "test_img = os.path.join(base_path, \"test\")\n",
        "\n",
        "test_file = glob(test_img+\"/*.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2fzHqjaa2WZ"
      },
      "outputs": [],
      "source": [
        "len(test_file), test_file[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = torch.load('/home/ubuntu/mmdet512/output/model/epoch_3.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgZnyGkGhoZ"
      },
      "source": [
        "테스트 데이터 하나를 추론해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ooe3M0fcnHB"
      },
      "outputs": [],
      "source": [
        "img = mmcv.imread(test_file[844])\n",
        "\n",
        "model.cfg = cfg\n",
        "predictions = inference_detector(model, img)\n",
        "show_result_pyplot(model, img, predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoPgWy8qGpq6"
      },
      "source": [
        "predictions의 길이는 4입니다. 이 4는 class의 개수를 의미하며\n",
        "config에서 지정해준 순서대로, 즉 간단한 이름으로 01, 02, 04, 05를 나타냅니다.\n",
        "\n",
        "따라서, 아래와 같은 경우 6개의 01 라벨과 5개의 05 라벨이 탐지되었다는 의미입니다.\n",
        "\n",
        "하지만 위 사진을 보면 두 개만 시각화되었는데 11개의 탐지된 결과 중 기본 지정 threshold인 0.3을 넘는 데이터가 두 개 뿐이었기 때문입니다.\n",
        "\n",
        "각 탐지된 결과는 5개의 element를 갖는데 앞의 4개가 bbox 좌표(x_min, y_min, x_max, y_max), 마지막 하나가 score(confidence)입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hGT9w7TcxIQ"
      },
      "outputs": [],
      "source": [
        "len(predictions), predictions[0].shape, predictions[1].shape, predictions[2].shape, predictions[3].shape,predictions[4].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWwCBYlnHSgE"
      },
      "source": [
        "01 라벨의 스코어들을 보니 가장 첫 번째 탐지 결과만 살아남아 시각화된 걸 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMFgfiRFH2k6"
      },
      "source": [
        "모든 테스트 데이터에 대해 추론을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df= pd.read_csv('/home/ubuntu/mmdet512/input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_prediction_string(labels, boxes, scores):\n",
        "    pred_strings = []\n",
        "    for j in zip(labels, scores, boxes):\n",
        "        pred_strings.append(\"{0} {1:.4f} {2} {3} {4} {5}\".format(\n",
        "            j[0], j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n",
        "        # labels scores box_xmin  box_xmax box_ymin box_ymax     \n",
        "    return \" \".join(pred_strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a356W2zciQ87"
      },
      "outputs": [],
      "source": [
        "# Ref : https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer?scriptVersionId=68887943&cellId=21\n",
        "\n",
        "\n",
        "score_threshold = 0.4 # 0.8, 0.3, cfg.model.test_cfg.rcnn.score_thr\n",
        "results = []\n",
        "\n",
        "\n",
        "for index, img_path in tqdm(enumerate(test_file), total = len(test_file)):\n",
        "        \n",
        "    image_id = img_path.split(\"/\")[-1].split(\".\")[0]\n",
        "    file_name = img_path.split(\"/\")[-1].split(\".\")[0]+\".png\"\n",
        "    result = {\n",
        "        'image_id': image_id,\n",
        "        'PredictionString': '14 1.0 0 0 1 1'\n",
        "    }\n",
        "\n",
        "    img = mmcv.imread(img_path)\n",
        "    predictions = inference_detector(model, img)\n",
        "\n",
        "    boxes, scores, labels = (list(), list(), list())\n",
        "\n",
        "    for k, cls_result in enumerate(predictions):\n",
        "        # print(\"cls_result\", cls_result)\n",
        "        if cls_result.size != 0:\n",
        "            if len(labels)==0:\n",
        "                boxes = np.array(cls_result[:, :4])\n",
        "                scores = np.array(cls_result[:, 4])\n",
        "                labels = np.array([k+1]*len(cls_result[:, 4]))\n",
        "            else:    \n",
        "                boxes = np.concatenate((boxes, np.array(cls_result[:, :4])))\n",
        "                scores = np.concatenate((scores, np.array(cls_result[:, 4])))\n",
        "                labels = np.concatenate((labels, [k+1]*len(cls_result[:, 4])))\n",
        "\n",
        "    if len(labels) != 0:\n",
        "        # 라벨 -1 씩 SHIFT\n",
        "        labels = labels - 1\n",
        "        # no finding 이 -1에서 14로 이동!\n",
        "        labels[labels == -1] = 14\n",
        "\n",
        "        indexes = np.where(scores > score_threshold)\n",
        "        # print(indexes)\n",
        "        \n",
        "        # 512절대좌표\n",
        "        boxes = boxes[indexes]\n",
        "\n",
        "\n",
        "        # 512 상대좌표\n",
        "        boxes_relative=boxes/512.0\n",
        "        \n",
        "        # test 해상도 width, height\n",
        "        test = test_df[test_df['image_id'] == image_id]\n",
        "        test_width = float(test['width'])\n",
        "        test_height = float(test['height'])\n",
        "\n",
        "        # xmin ymin xmax ymax\n",
        "        # x * width\n",
        "        # y * height\n",
        "        for i,box in enumerate(boxes_relative):\n",
        "            box[0] = float(box[0] * test_width)\n",
        "            box[1] = float(box[1] * test_height) \n",
        "            box[2] = float(box[2] * test_width)\n",
        "            box[3] = float(box[3] * test_height)\n",
        "\n",
        "        # 최종 좌표\n",
        "        boxes = boxes_relative\n",
        "        scores = scores[indexes]\n",
        "        labels = labels[indexes]\n",
        "        \n",
        "        # 0.5 보다 confidence 높은 박스가 있다는 의미\n",
        "        if len(boxes) > 0:\n",
        "          result = {\n",
        "              'image_id': image_id,\n",
        "              'PredictionString': format_prediction_string(labels, boxes, scores)\n",
        "          }\n",
        "    # result list를 계속 append!\n",
        "    results.append(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvbYFhSHaA8K"
      },
      "source": [
        "##Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM0DgQfcndjA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "submission = pd.DataFrame(results)\n",
        "submission.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zcpm4fEngog"
      },
      "outputs": [],
      "source": [
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szOjQhZinfmO"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('/home/ubuntu/mmdet512/output/mmdedtection_baseline.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('pytorch112_p38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "58d57aa79b850236b521150a1202e790a96ac8259ac3baa83cc74f3e58246589"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca6f56434984541be800c2e9843d457": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108f45e280b24f44836e4df715891af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e2411c8c715496fa92ffddee4347d62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248db45df90c486b8c7425e2fa99df82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407d88b1e12f4544b3b5f9f2e698dd39",
            "placeholder": "​",
            "style": "IPY_MODEL_108f45e280b24f44836e4df715891af5",
            "value": "100%"
          }
        },
        "2d029adb381e4e47ba3da0108560fc20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301cbfac20a640f29e8476d466698839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5335184cebf84a2ea91407337fb60cda",
            "placeholder": "​",
            "style": "IPY_MODEL_f72da8ff758745d59d9ef634970bfb36",
            "value": " 20874/20874 [03:57&lt;00:00, 89.43it/s]"
          }
        },
        "386f84edab764cd2be78ecdadd696786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e6a598b7fe4768adb163b2434ceba9",
            "max": 3516,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac2cb33dd3f64609a96bfc82da0579b6",
            "value": 3516
          }
        },
        "407d88b1e12f4544b3b5f9f2e698dd39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487909f72eb84fad8571115f72981f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49facae0b2b3409e9b688d1c1f6db3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ae1394ec0b4c31b55f71d5246ab38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca6f56434984541be800c2e9843d457",
            "max": 20874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_789e9fc03f2c4927891a306492700a50",
            "value": 20874
          }
        },
        "5335184cebf84a2ea91407337fb60cda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f214eac68ee48b3b69c198f10d1f383": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643b91e104c54e6597f65476fb186b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248db45df90c486b8c7425e2fa99df82",
              "IPY_MODEL_386f84edab764cd2be78ecdadd696786",
              "IPY_MODEL_a548af1bca1c492aa942e66d9e0dd43e"
            ],
            "layout": "IPY_MODEL_d537ede18db94f24889a3736af33c412"
          }
        },
        "73685fe8004d4d3fae52beb4eab712e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2411c8c715496fa92ffddee4347d62",
            "placeholder": "​",
            "style": "IPY_MODEL_7fbfc7fe65674abfb5e3819aa9616b7d",
            "value": "100%"
          }
        },
        "789e9fc03f2c4927891a306492700a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d3b39f4e81048f0adacacdd94c4ab79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49facae0b2b3409e9b688d1c1f6db3c7",
            "placeholder": "​",
            "style": "IPY_MODEL_add6cff76ea34ec1a99ab79e5984db7e",
            "value": "100%"
          }
        },
        "7fbfc7fe65674abfb5e3819aa9616b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a6c16992674c6ea87dc15dc33588a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73685fe8004d4d3fae52beb4eab712e5",
              "IPY_MODEL_c4e8736f4dd04726aef6464cd69ab74b",
              "IPY_MODEL_cb006118a674438a8ac0c3b7eeaabaec"
            ],
            "layout": "IPY_MODEL_2d029adb381e4e47ba3da0108560fc20"
          }
        },
        "92bedbc53cf847bfa5dc804ac7bc62b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e6a598b7fe4768adb163b2434ceba9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3217f4f380244f180983a0b85e37f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d3b39f4e81048f0adacacdd94c4ab79",
              "IPY_MODEL_52ae1394ec0b4c31b55f71d5246ab38b",
              "IPY_MODEL_301cbfac20a640f29e8476d466698839"
            ],
            "layout": "IPY_MODEL_92bedbc53cf847bfa5dc804ac7bc62b7"
          }
        },
        "a548af1bca1c492aa942e66d9e0dd43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f214eac68ee48b3b69c198f10d1f383",
            "placeholder": "​",
            "style": "IPY_MODEL_d3b2f8ad41f74bcb857a67a901ffe3e4",
            "value": " 3516/3516 [00:07&lt;00:00, 440.67it/s]"
          }
        },
        "ac2cb33dd3f64609a96bfc82da0579b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "add6cff76ea34ec1a99ab79e5984db7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4e8736f4dd04726aef6464cd69ab74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487909f72eb84fad8571115f72981f6c",
            "max": 878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfc9b2667c36433f85ac86f2d09bea31",
            "value": 878
          }
        },
        "cb006118a674438a8ac0c3b7eeaabaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3feb19df1b44362b34d44ff06ceeeed",
            "placeholder": "​",
            "style": "IPY_MODEL_f59fb9933ecf44e4a612e2eeaf07d544",
            "value": " 878/878 [00:00&lt;00:00, 1088.69it/s]"
          }
        },
        "cfc9b2667c36433f85ac86f2d09bea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3b2f8ad41f74bcb857a67a901ffe3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d537ede18db94f24889a3736af33c412": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3feb19df1b44362b34d44ff06ceeeed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59fb9933ecf44e4a612e2eeaf07d544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f72da8ff758745d59d9ef634970bfb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
